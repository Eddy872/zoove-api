from fastapi import FastAPI
from pydantic import BaseModel
import os
from openai import OpenAI
import logging

# ğŸ” Initialise le client OpenAI avec clÃ© API depuis les variables d'env
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# ğŸ§  Logs
logging.basicConfig(level=logging.INFO)
print("âœ… Lancement de l'API Zoove avec GPT-3.5...")

app = FastAPI()

class Request(BaseModel):
    species: str
    message: str

@app.get("/")
def read_root():
    return {"message": "Bienvenue sur lâ€™API Zoove ğŸ¤–"}

@app.get("/ping")
def ping():
    return {"status": "ok"}

@app.post("/chat")
def chat_with_zoove(req: Request):
    print("ğŸ“¥ RequÃªte reÃ§ue")

    # ğŸ“ Construction du prompt en langage naturel
    prompt = f"""Tu es Zoove, un assistant expert en comportement animal.
RÃ©ponds toujours en franÃ§ais, de maniÃ¨re bienveillante et claire.

EspÃ¨ce : {req.species}
Utilisateur : {req.message}
Zoove :"""

    print(f"ğŸ“ Prompt envoyÃ© Ã  OpenAI :\n{prompt}")

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "Tu es Zoove, un assistant animalier intelligent."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=200
    )

    print("âœ… RÃ©ponse gÃ©nÃ©rÃ©e")
    return {"response": response.choices[0].message.content.strip()}
